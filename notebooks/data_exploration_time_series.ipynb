{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Airbnb Price Prediction - Data Exploration\n",
    "Use dataset published by Kaggle - https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data - to train a simple deep learning model to predict prices for Airbnb properties.\n",
    "\n",
    "This notebook contains the code to explore the dataset using time series approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "- load pickled dataframe containing data loaded from source XLS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels as sm\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "# common imports\n",
    "import zipfile\n",
    "import time\n",
    "# import datetime, timedelta\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date\n",
    "from dateutil import relativedelta\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from io import StringIO\n",
    "import requests\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import os\n",
    "import math\n",
    "from subprocess import check_output\n",
    "from IPython.display import display\n",
    "import logging\n",
    "import yaml\n",
    "from collections import Counter\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(config_file):\n",
    "    ''' open config file with name config_file that contains parameters\n",
    "    for this module and return Python object\n",
    "\n",
    "    Args:\n",
    "        config_file: filename containing config parameters\n",
    "\n",
    "    Returns:\n",
    "        config: Python dictionary with config parms from config file - dictionary\n",
    "\n",
    "\n",
    "    '''\n",
    "    current_path = os.getcwd()\n",
    "    print(\"current directory is: \" + current_path)\n",
    "\n",
    "    path_to_yaml = os.path.join(current_path, config_file)\n",
    "    print(\"path_to_yaml \" + path_to_yaml)\n",
    "    try:\n",
    "        with open(path_to_yaml, 'r') as c_file:\n",
    "            config = yaml.safe_load(c_file)\n",
    "        return config\n",
    "    except Exception as error:\n",
    "        print('Error reading the config file ' + error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1817ca2daf90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# common variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# control whether to load data from scratch from original source or from saved dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mload_from_scratch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'general'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'load_from_scratch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# control whether to save dataframe with transformed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msave_transformed_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'general'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'save_transformed_dataframe'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "# common variables\n",
    "# control whether to load data from scratch from original source or from saved dataframe\n",
    "load_from_scratch = config['general']['load_from_scratch']\n",
    "# control whether to save dataframe with transformed data\n",
    "save_transformed_dataframe = config['general']['save_transformed_dataframe']\n",
    "# control whether rows containing erroneous values are removed from the saved dataset\n",
    "remove_bad_values = config['general']['remove_bad_values']\n",
    "# name of file containing pickled dataframe version of input (unprocessed) dataset\n",
    "pickled_input_dataframe = config['file_names']['pickled_input_dataframe']\n",
    "# name of file to which prepared data set is saved as a pickled dataframe\n",
    "pickled_output_dataframe = config['file_names']['pickled_output_dataframe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is in a directory called \"data\" that is a sibling to the directory containing the notebook\n",
    "# this code assumes you have copied to this directory all the XLS files from the source dataset: https://www.toronto.ca/city-government/data-research-maps/open-data/open-data-catalogue/#e8f359f0-2f47-3058-bf64-6ec488de52da\n",
    "rawpath = os.getcwd()\n",
    "print(\"raw path is\",rawpath)\n",
    "path = os.path.abspath(os.path.join(rawpath, '..', 'data'))\n",
    "print(\"path is\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_feature_categories(df):\n",
    "    allcols = list(df)\n",
    "    print(\"all cols\",allcols)\n",
    "    textcols = ['Incident','Location'] # \n",
    "    continuouscols = ['Min Delay','Min Gap'] \n",
    "                      # columns to deal with as continuous values - no embeddings\n",
    "    timecols = ['Report Date','Time']\n",
    "    collist = ['Day','Vehicle','Route','Direction']\n",
    "    for col in continuouscols:\n",
    "        df[col] = df[col].astype(float)\n",
    "    print('texcols: ',textcols)\n",
    "    print('continuouscols: ',continuouscols)\n",
    "    print('timecols: ',timecols)\n",
    "    print('collist: ',collist)\n",
    "    return(allcols,textcols,continuouscols,timecols,collist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(dataset):\n",
    "    print(\"before mv\")\n",
    "    for col in collist:\n",
    "        dataset[col].fillna(value=\"missing\", inplace=True)\n",
    "    for col in continuouscols:\n",
    "        dataset[col].fillna(value=0.0,inplace=True)\n",
    "    for col in textcols:\n",
    "        dataset[col].fillna(value=\"missing\", inplace=True)\n",
    "    return (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_time(date_time_value,time_value):\n",
    "    ''' given a datetime replace the time portion '''\n",
    "     \n",
    "    date_time_value = date_time_value.replace(hour=time_value.hour,minute=time_value.minute,second=time_value.minute)\n",
    "    return(date_time_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataframe and add columns for time series manipulation\n",
    "- load pickled dataframe\n",
    "- show info about the dataset\n",
    "- build index combining date+time along with labelled column date+time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickled dataframe\n",
    "df = pd.read_pickle(os.path.join(path,pickled_input_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure Route and Vehicle are strings, not numeric\n",
    "# df = df.astype({\"Route\": str, \"Vehicle\": int})\n",
    "df['Route'] = df['Route'].astype(str)\n",
    "df['Vehicle'] = df['Vehicle'].astype(str)\n",
    "# df['filename'] = df['filename'].str[:-4]\n",
    "df['Vehicle'] = df['Vehicle'].str[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define categories\n",
    "allcols,textcols,continuouscols,timecols,collist = define_feature_categories(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing values\n",
    "df = fill_missing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting some information about dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting some information about dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# further Analysis \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column combing date + time (needed for resampling) and make it the index\n",
    "\n",
    "\n",
    "df.index = df.apply(lambda x: replace_time(x['Report Date'], x['Time']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframes for delay-duration based forecasting\n",
    "- create a dataframe with just index and delay\n",
    "- resample to get mean by month in year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new = old[['A', 'C', 'D']].copy()\n",
    "# new dataframe with just Min Delay column\n",
    "dfstrip = df[['Min Delay']].copy()\n",
    "dfstrip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmonthav = dfstrip.resample('M').mean()\n",
    "dfmonthav.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['new'] = df3.index\n",
    "dfmonthav['Report Date Time'] = dfmonthav.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmonthav.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe for delay count based forecasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfstrip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmonthcount = dfstrip.resample('M').count()\n",
    "# df = df.rename(columns={'oldName1': 'newName1', 'oldName2': 'newName2'})\n",
    "dfmonthcount = dfmonthcount.rename(columns={'Min Delay':'Delay Count'})\n",
    "dfmonthcount.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmonthcount['Report Date Time'] = dfmonthcount.index\n",
    "dfmonthcount.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data = merged_data.join(dm_cases.set_index('CASE_NUMBER'), on = 'CASE_NUMBER')\n",
    "dfmonthav = dfmonthav.join(dfmonthcount, on='Report Date Time',lsuffix='_left', rsuffix='_right')\n",
    "dfmonthav.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmonthav.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmonthav = dfmonthav.rename(columns={'Report Date Time_left':'Report Date Time'})\n",
    "dfmonthav.drop(['Report Date Time_right'],axis=1)\n",
    "dfmonthav.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmonthav.drop(['Report Date Time_right'],axis=1)\n",
    "dfmonthav.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmonthav['Min Delay'].plot(legend=True)\n",
    "# df.B.plot(secondary_y=True, style='g')\n",
    "dfmonthav['Delay Count'].plot(secondary_y=True, style='g',legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ax.set_ylabel('Average Delay')\n",
    "#ax.right_ax.set_ylabel('Number of delays')\n",
    "plt.rcParams[\"figure.figsize\"] = [8,4]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting\n",
    "**Trend** - Trend shows the variation in the output as time increases, often in a non-linear fashion. \n",
    "\n",
    "**Level** - The baseline value for a time series.\n",
    "\n",
    "**Seasonality** - is a characteristic of a time series in which the data experiences regular and predictable changes that recur every calendar year. Any predictable fluctuation or pattern that recurs or repeats over a one-year period is said to be seasonal - from https://www.investopedia.com/terms/s/seasonality.asp\n",
    "\n",
    "**Noise** - Random variation in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmonthav.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to make scatter plot by month convenient\n",
    "dfmonthav['Month'] = dfmonthav['Report Date Time'].dt.month\n",
    "dfmonthav.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmonthav.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot to show mean delay in same month across years\n",
    "dfmonthav.plot.scatter(x = 'Month', y = 'Min Delay')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot to show delay count in same month across years\n",
    "dfmonthav.plot.scatter(x = 'Month', y = 'Delay Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Analysis\n",
    "\n",
    "Use the built-in Pandas rolling function to smooth the data.\n",
    "\n",
    "For trend analysis, we use smoothing techniques. \n",
    "- In statistics smoothing a data set means to create an approximating function that attempts to capture important patterns in the data, while leaving out noise or other fine-scale structures/rapid phenomena. \n",
    "- In smoothing, the data points of a signal are modified so individual points (presumably because of noise) are reduced, and points that are lower than the adjacent points are increased leading to a smoother signal. \n",
    "\n",
    "We implement smoothing by taking moving averages. [Exponential moving average](https://www.investopedia.com/terms/e/ema.asp) is frequently used to compute smoothed function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_delay = dfmonthav[['Min Delay']]\n",
    "count_delay = dfmonthav[['Delay Count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_delay.rolling(6).mean().plot(figsize=(20,10), linewidth=5, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_delay.rolling(6).mean().plot(figsize=(20,10), linewidth=5, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonality Analysis\n",
    "\n",
    "Two examples of seasonality analysis algorithms are:\n",
    "\n",
    "[Using 1st discrete difference of object](https://machinelearningmastery.com/difference-time-series-dataset-python/)\n",
    "\n",
    "[Periodicity and Autocorrelation](https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 1st discrete difference of object\n",
    "# This gives us idea about variation of data for a period of time.\n",
    "mean_delay.diff(periods=4).plot(figsize=(20,10), linewidth=5, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_delay.diff(periods=4).plot(figsize=(20,10), linewidth=5, fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto correlation is the most famous way to understand seasonal variation till now. We can calculate the correlation for time series observations with observations with previous time steps, called lags. Because the correlation of the time series observations is calculated with values of the same series at previous times, this is called a serial correlation, or an autocorrelation.In this plot vertical axis is represented by the following equations:-\n",
    "\n",
    "> $C_n = \\sum_{t = 1}^{n - h} (y(t) - \\hat{y}) (y(t + n) - \\hat{y}) / n$\n",
    "\n",
    "> $C_0 = \\sum_{t = 1}^{n} (y(t) - \\hat{y})^2 / n$\n",
    "\n",
    "Horizontal axis represents time lag(previous time steps)  h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_delay = dfmonthav[['Min Delay']]\n",
    "# count_delay = dfmonthav[['Delay Count']]\n",
    "\n",
    "\n",
    "pd.plotting.autocorrelation_plot(dfmonthav['Min Delay'])\n",
    "plt.show()\n",
    "# The following curve represents the relation between current time step and its previous time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.autocorrelation_plot(dfmonthav['Delay Count'])\n",
    "plt.show()\n",
    "# The following curve represents the relation between current time step and its previous time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.lag_plot(dfmonthav['Min Delay'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.lag_plot(dfmonthav['Delay Count'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
